{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nax050Dybrim",
        "outputId": "8a1ea8e2-d047-4cfb-9d8d-bef0dc07ae3a"
      },
      "outputs": [],
      "source": [
        "# import the required items \n",
        "import onnx\n",
        "import onnxruntime as ort\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5AQQW0vSbzB8"
      },
      "outputs": [],
      "source": [
        "model_path = '../../results/models/onnx_dive/model.onnx'\n",
        "# image_path = '../../results/others/picture_1.jpg'\n",
        "label_path = '../../results/models/onnx_dive/label_map.pbtxt'\n",
        "video_path = '../../results/others/gopro_trimmed.mp4'\n",
        "out_frames_path = '../../results/others/frames'\n",
        "video_out_path = '../../results/others'\n",
        "\n",
        "# enter the required details below \n",
        "width = 640\n",
        "height = 640\n",
        "num_classes=3\n",
        "conf_thre=0.1\n",
        "nms_thre=0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7VvjYQtAe3Vi"
      },
      "outputs": [],
      "source": [
        "# simple function to load a single image \n",
        "def load_image_into_numpy_array(path, height, width):\n",
        "    \"\"\"\n",
        "    Load an image from file into a numpy array.\n",
        "\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "      height: height of image\n",
        "      width: width of image\n",
        "\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3), (original_height, original_width)\n",
        "    \"\"\"\n",
        "    image = Image.open(path).convert(\"RGB\")\n",
        "    image_shape = np.asarray(image).shape\n",
        "\n",
        "    image_resized = image.resize((width, height))\n",
        "    return np.array(image_resized), (image_shape[0], image_shape[1])\n",
        "\n",
        "\n",
        "def convert_cv_image(cv_img, height, width):\n",
        "    img = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n",
        "    img_shape = img.shape\n",
        "\n",
        "    img_resized = cv2.resize(img, (width, height))\n",
        "    \n",
        "    return np.array(img_resized), (img_shape[0], img_shape[1])\n",
        "    \n",
        "\n",
        "# simple function to read the label file label.pbtxt\n",
        "def load_label_map(label_map_path):\n",
        "    \"\"\"\n",
        "    Reads label map in the format of .pbtxt and parse into dictionary\n",
        "\n",
        "    Args:\n",
        "      label_map_path: the file path to the label_map\n",
        "\n",
        "    Returns:\n",
        "      dictionary with the format of {label_index: {'id': label_index, 'name': label_name}}\n",
        "    \"\"\"\n",
        "    # creates the empty dictionary\n",
        "    label_map = {}\n",
        "\n",
        "    with open(label_map_path, \"r\") as label_file:\n",
        "        for line in label_file:\n",
        "            if \"id\" in line:\n",
        "                label_index = int(line.split(\":\")[-1])\n",
        "                label_name = next(label_file).split(\":\")[-1].strip().strip(\"'\")\n",
        "                label_map[label_index] = {\n",
        "                    \"id\": label_index,\n",
        "                    \"name\": label_name,\n",
        "                }\n",
        "    # outputs the dictionary of the label values \n",
        "    return label_map\n",
        "\n",
        "def post_process(rows_8400, num_classes, conf_thre=0.0001, nms_thre=0.3, print_info=False):\n",
        "    \"\"\"\n",
        "    Process onnx output and apply filtering using confidence & NMS threshold \n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # makes a copy of the input \n",
        "    prediction = np.copy(rows_8400)\n",
        "    # convert the copy to a tensor \n",
        "    prediction = torch.Tensor(prediction)\n",
        "\n",
        "    if print_info == True:\n",
        "        print('Here is the input shape:',prediction.shape, '\\n')\n",
        "        print('Here is the input data:','\\n',prediction, '\\n')\n",
        "\n",
        "    # make a placeholder tensor of normal distribution/random values \n",
        "    # we use this tensor to hold our calculated box positions temporarily \n",
        "    box_corner = prediction.new(prediction.shape)\n",
        "    if print_info == True:\n",
        "        print('here is the created placeholder tensor:','\\n',box_corner, '\\n')\n",
        "\n",
        "    # perform some column maths magic to get the values for boxes location\n",
        "    # col 0 - col 2 \n",
        "    box_corner[:, :, 0] = prediction[:, :, 0] - prediction[:, :, 2] / 2\n",
        "    # col 1 - col 3 \n",
        "    box_corner[:, :, 1] = prediction[:, :, 1] - prediction[:, :, 3] / 2\n",
        "    # col 0 + col 2 \n",
        "    box_corner[:, :, 2] = prediction[:, :, 0] + prediction[:, :, 2] / 2\n",
        "    # col 1 + col 3 \n",
        "    box_corner[:, :, 3] = prediction[:, :, 1] + prediction[:, :, 3] / 2\n",
        "    # replace with new format \n",
        "    prediction[:, :, :4] = box_corner[:, :, :4]\n",
        "    # show the new prediction \n",
        "    if print_info == True:\n",
        "        print('here is the updated 8400 rows of tensor with adjusted box coordinates:','\\n',prediction, '\\n')\n",
        "\n",
        "    # trail and error to find the right column to start \n",
        "    x_fac = 6\n",
        "\n",
        "    # print the class probabilities\n",
        "    if print_info == True:\n",
        "        print('here are the class probabilities:','\\n',prediction[:, :, x_fac: x_fac + num_classes], '\\n')\n",
        "    \n",
        "    # need to adjust the dimension based on the number of input classes \n",
        "    if num_classes > 1:\n",
        "        dims = 2\n",
        "    else:\n",
        "        dims = 0\n",
        "    # print(dims)\n",
        "    # get the class confidence and the index of the predicted class \n",
        "    class_conf, class_pred = torch.max(prediction[:, :, x_fac: x_fac + num_classes], dims, keepdim=True)\n",
        "\n",
        "    # get the masking for the rows above conf_thre\n",
        "    conf_mask = (prediction[:,:, 4] * class_conf.squeeze() >= conf_thre).squeeze()\n",
        "\n",
        "    # output the numebr of rows that are >= conf_thre\n",
        "    rows_picked = 0 \n",
        "    for i in conf_mask: \n",
        "        if i == True:\n",
        "            rows_picked += 1\n",
        "\n",
        "    if print_info == True:\n",
        "        print('rows picked based on confidence threshold:',rows_picked, '\\n')\n",
        "\n",
        "    # concat all the newly prepared data into a new output tensor \n",
        "    detections = torch.cat((prediction[:, :, :5], class_conf, class_pred.float()), 2)\n",
        "\n",
        "    # apply masking to the 8400 rows, we only keep thos rows with > conf_thres \n",
        "    detections = detections[:,conf_mask,:]\n",
        "    if print_info == True:\n",
        "        print('after masking:','\\n', detections)\n",
        "\n",
        "    # apply the NMS to reduce the number of overlapping boxes \n",
        "    d = detections[:, :, :4]\n",
        "    d = d.view(len(detections[0]), 4)\n",
        "    d.shape\n",
        "\n",
        "    s = detections[:, :, 4] * detections[:, :, 5]\n",
        "    s = s.view(len(detections[0]))\n",
        "    s.shape\n",
        "\n",
        "    id = detections[:, :, 6]\n",
        "    id = id.view(len(detections[0]))\n",
        "    id.shape\n",
        "    \n",
        "    # aglgorithm here \n",
        "    nms_out_index = torchvision.ops.batched_nms(\n",
        "        d,\n",
        "        s,\n",
        "        id,\n",
        "        nms_thre,\n",
        "    )\n",
        "    if print_info == True:\n",
        "        print('after NMS, rows pickedfor plotting:','\\n',nms_out_index, '\\n')\n",
        "    \n",
        "    # apply the NMS masking \n",
        "    output = detections[0][nms_out_index]\n",
        "\n",
        "    # return the final output \n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_model(model_path, verbose=False):\n",
        "    # test model \n",
        "    onnx_model = onnx.load(model_path)\n",
        "    onnx.checker.check_model(onnx_model)\n",
        "\n",
        "    # Load model\n",
        "    if verbose:\n",
        "        print(\"Loading model...\")\n",
        "    start_time = time.time()\n",
        "    session = ort.InferenceSession(model_path)\n",
        "    if verbose:\n",
        "        print(\"Model loaded, took {} seconds...\".format(time.time() - start_time))\n",
        "\n",
        "    # get the name of the input and output \n",
        "    input_name = session.get_inputs()[0].name\n",
        "    output_name = session.get_outputs()[0].name\n",
        "\n",
        "    return session, input_name, output_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pred_single_image(image_path, width, height, session, input_name, output_name, num_classes, conf_thre, nms_thre):\n",
        "    # Returned resized + original picture in the format of width, height\n",
        "    if isinstance(image_path, str):\n",
        "        image_resized, origi_shape = load_image_into_numpy_array(image_path, int(width), int(height))\n",
        "    else:\n",
        "        image_resized, origi_shape = convert_cv_image(image_path, int(width), int(height))\n",
        "\n",
        "    # preprocess the resized image so we can input them proper \n",
        "    input_image = np.expand_dims(image_resized.astype(np.float32).transpose(2,0,1),0)\n",
        "\n",
        "    ## Feed image into model\n",
        "    ort_outs = session.run([output_name],{input_name: input_image})\n",
        "\n",
        "    # process onnx output and apply filtering using confidence & NMS threshold \n",
        "    output = post_process(ort_outs[0], num_classes, conf_thre=conf_thre, nms_thre=nms_thre, print_info=False)\n",
        "    if output.shape[0] == 0:\n",
        "        print('no bounding boxes were identified !')\n",
        "\n",
        "    return output, image_resized, origi_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# session, input_name, output_name = load_model(model_path)\n",
        "# output, image_resized, origi_shape = pred_single_image(image_path, width, height, session, input_name, output_name, num_classes, conf_thre, nms_thre)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjPL9-Q9cC_y",
        "outputId": "01af8339-96f3-4189-f340-89cbdd127581"
      },
      "outputs": [],
      "source": [
        "# # test model \n",
        "# onnx_model = onnx.load(model_path)\n",
        "# onnx.checker.check_model(onnx_model)\n",
        "\n",
        "# # Load model\n",
        "# print(\"Loading model...\")\n",
        "# start_time = time.time()\n",
        "# session = ort.InferenceSession(model_path)\n",
        "# print(\"Model loaded, took {} seconds...\".format(time.time() - start_time))\n",
        "\n",
        "# # get the name of the input and output \n",
        "# input_name = session.get_inputs()[0].name\n",
        "# output_name = session.get_outputs()[0].name\n",
        "\n",
        "# ## Returned resized + original picture in the format of width, height\n",
        "# image_resized, origi_shape = load_image_into_numpy_array(image_path, int(width), int(height))\n",
        "\n",
        "# # preprocess the resized image so we can input them proper \n",
        "# input_image = np.expand_dims(image_resized.astype(np.float32).transpose(2,0,1),0)\n",
        "\n",
        "# ## Feed image into model\n",
        "# ort_outs = session.run([output_name],{input_name: input_image})\n",
        "\n",
        "# # show the ouput\n",
        "# ort_outs[0][0][0:3]\n",
        "\n",
        "# # process onnx output and apply filtering using confidence & NMS threshold \n",
        "# output = post_process(ort_outs[0], num_classes, conf_thre=conf_thre, nms_thre=nms_thre, print_info=False)\n",
        "# if output.shape[0] == 0:\n",
        "#     print('no bounding boxes were identified !')\n",
        "# output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_bbox_class_score(onnx_output, width, height):\n",
        "\n",
        "    # get the plotting information from the post processed outputs \n",
        "    bboxes = onnx_output[:, 0:4].cpu().detach().numpy().astype(np.float64)\n",
        "    classes = onnx_output[:,6].cpu().detach().numpy().astype(np.float64)\n",
        "    scores = (onnx_output[:,4]*onnx_output[:,5]).cpu().detach().numpy().astype(np.float64)\n",
        "\n",
        "    # perform some simple maths \n",
        "    bboxes = [\n",
        "        [   bbox[1]/height,\n",
        "            bbox[0]/width,\n",
        "            bbox[3]/height,\n",
        "            bbox[2]/width,\n",
        "        ]\n",
        "        for bbox in bboxes\n",
        "    ]\n",
        "\n",
        "    return bboxes, classes, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def draw_on_image(image_resized, origi_shape, bboxes, classes, scores, label_path, show_image=False):\n",
        "\n",
        "    # get the original image \n",
        "    image_origi = Image.fromarray(image_resized).resize((origi_shape[1], origi_shape[0]))\n",
        "    # make into numpy array\n",
        "    image_origi = np.array(image_origi)\n",
        "\n",
        "    ## Load label map\n",
        "    category_index = load_label_map(label_path)\n",
        "    category_index\n",
        "\n",
        "    np.random.seed(0)\n",
        "    ## Load color map\n",
        "    color_map = {}\n",
        "    for each_class in range(len(category_index)):\n",
        "        color_map[each_class] = [\n",
        "                                int(np.random.choice(range(256))),\n",
        "                                int(np.random.choice(range(256))), \n",
        "                                int(np.random.choice(range(256))),\n",
        "        \n",
        "            # int(i) for i in np.random.choice(range(256), size=3)\n",
        "    ]\n",
        "\n",
        "    # plot all the boxes for our current picture\n",
        "    for idx, each_bbox in enumerate(bboxes):\n",
        "        color = color_map.get(classes[idx])\n",
        "        # print('plotted box',idx)\n",
        "        # print('color:',color)\n",
        "\n",
        "        ## Draw bounding box\n",
        "        cv2.rectangle(\n",
        "            image_origi,\n",
        "            (\n",
        "                int(each_bbox[1] * origi_shape[1]),\n",
        "                int(each_bbox[0] * origi_shape[0]),\n",
        "            ),\n",
        "            (\n",
        "                int(each_bbox[3] * origi_shape[1]),\n",
        "                int(each_bbox[2] * origi_shape[0]),\n",
        "            ),\n",
        "            color,\n",
        "            2,\n",
        "        )\n",
        "\n",
        "        ## Draw label background\n",
        "        cv2.rectangle(\n",
        "            image_origi,\n",
        "            (\n",
        "                int(each_bbox[1] * origi_shape[1]),\n",
        "                int(each_bbox[2] * origi_shape[0]),\n",
        "            ),\n",
        "            (\n",
        "                int(each_bbox[3] * origi_shape[1]),\n",
        "                int(each_bbox[2] * origi_shape[0] + 15),\n",
        "            ),\n",
        "            color,\n",
        "            -1,\n",
        "        )\n",
        "\n",
        "        ## Insert label class & score\n",
        "        cv2.putText(\n",
        "            image_origi,\n",
        "            \"Class: {}, Score: {}\".format(\n",
        "                str(category_index[classes[idx]+1][\"name\"]),\n",
        "                str(round(scores[idx], 2)),\n",
        "            ),\n",
        "            (\n",
        "                int(each_bbox[1] * origi_shape[1]),\n",
        "                int(each_bbox[2] * origi_shape[0] + 10),\n",
        "            ),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            0.3,\n",
        "            (255, 255, 255),\n",
        "            1,\n",
        "            cv2.LINE_AA,\n",
        "        )\n",
        "\n",
        "    image_predict = Image.fromarray(image_origi)\n",
        "    # image_predict\n",
        "    if show_image:\n",
        "        plt.imshow(image_predict)\n",
        "\n",
        "    return image_predict\n",
        "    \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# bboxes, classes, scores = get_bbox_class_score(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# image_predict = draw_on_image(image_resized, origi_shape, bboxes, classes, scores, label_path, show_image=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def video_predict(\n",
        "    video_file,\n",
        "    output_path,\n",
        "    session,\n",
        "    input_name,\n",
        "    output_name,\n",
        "    label_path,\n",
        "    input_size,\n",
        "    num_classes,\n",
        "    conf_thre,\n",
        "    nms_thre,\n",
        "    verbose=False,\n",
        "):\n",
        "\n",
        "    \"\"\"Extract frames from a video file or youtube link\n",
        "\n",
        "    Args:\n",
        "    video_file (str): path to the video\n",
        "    output_path (str): path to output folder for storing extracted frames\n",
        "    session (onnx session): onnx session\n",
        "    input_name (str): onnx input name\n",
        "    output_name (str): onnx output name\n",
        "    label_path (str): path to label mapping .pbtxt file\n",
        "    input_size (tuple): onnx model image input size\n",
        "    num_classes (int): number of classes to predict\n",
        "    conf_thre (float): confidence threshold for filtering out bboxes\n",
        "    nms_thre (float): non-max supression threshold for filtering out bboxes\n",
        "    verbose (bool): whether to print inference related info\n",
        "\n",
        "    Return:\n",
        "    frame_predictions (list): list of numpy arrays of frames with bbox drawn\n",
        "    bbox_class_score (list): list of tuples for each frame's (bbox location, class, score)\n",
        "    orig_frames (list): list of numpy arrays of original frames\n",
        "    origi_shape (tuple): original shape of frames/video\n",
        "    fps (int): original fps of video\n",
        "    \"\"\"\n",
        "\n",
        "    if not os.path.exists(output_path):\n",
        "        os.makedirs(output_path)\n",
        "\n",
        "    vid = cv2.VideoCapture(video_file)\n",
        "\n",
        "    frame_predictions = []\n",
        "    orig_frames = []\n",
        "    bbox_class_score = []\n",
        "    fps = round(vid.get(cv2.CAP_PROP_FPS))\n",
        "    num_frames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    if verbose:\n",
        "        print(num_frames, \"frames detected!\")\n",
        "    index = 0\n",
        "    start_time = time.time()\n",
        "    while vid.isOpened():\n",
        "        success, img = vid.read()\n",
        "        index += 1\n",
        "        if success:\n",
        "            # extract every fps frame of the video and save\n",
        "            # cv2.imwrite(\n",
        "            #     output_path + \"/\" + str(index) + \".jpg\",\n",
        "            #     img,\n",
        "            # )\n",
        "            orig_frames.append(img)\n",
        "\n",
        "            frame_start_time = time.time()\n",
        "            # predict on image\n",
        "            onnx_output, image_resized, origi_shape = pred_single_image(\n",
        "                img,\n",
        "                input_size[0],\n",
        "                input_size[1],\n",
        "                session,\n",
        "                input_name,\n",
        "                output_name,\n",
        "                num_classes,\n",
        "                conf_thre,\n",
        "                nms_thre,\n",
        "            )\n",
        "            bboxes, classes, scores = get_bbox_class_score(\n",
        "                onnx_output, input_size[0], input_size[1]\n",
        "            )\n",
        "            image_predict = draw_on_image(\n",
        "                image_resized,\n",
        "                origi_shape,\n",
        "                bboxes,\n",
        "                classes,\n",
        "                scores,\n",
        "                label_path,\n",
        "                show_image=False,\n",
        "            )\n",
        "            bbox_class_score.append((bboxes, classes, scores))\n",
        "            frame_predictions.append(np.array(image_predict))\n",
        "            # save image_predict?\n",
        "            if verbose:\n",
        "                print(\n",
        "                    \"--- Frame inferred in %0.2f seconds ---\"\n",
        "                    % (time.time() - frame_start_time)\n",
        "                )\n",
        "\n",
        "        # stop reading at end of video\n",
        "        # need this as some frames return False success, so cannot\n",
        "        # use success to break the while loop\n",
        "        if index > num_frames:\n",
        "            break\n",
        "    vid.release()\n",
        "\n",
        "    print(\"--- Completed in %0.2f seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "    return frame_predictions, bbox_class_score, orig_frames, origi_shape, fps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def video_stitch(images_array, video_out_path, video_name, origi_shape, fps, RGB2BGR=True):\n",
        "\n",
        "    out_vid_bbox = cv2.VideoWriter(\n",
        "        os.path.join(video_out_path, video_name)+'.mp4', \n",
        "        cv2.VideoWriter_fourcc(*\"mp4v\"), \n",
        "        fps, (origi_shape[1], origi_shape[0])\n",
        "    )\n",
        "    for img_array in images_array:\n",
        "        if RGB2BGR:\n",
        "            out_vid_bbox.write(cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))\n",
        "        else:\n",
        "            out_vid_bbox.write(img_array)\n",
        "    out_vid_bbox.release()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model...\n",
            "Model loaded, took 0.19946670532226562 seconds...\n"
          ]
        }
      ],
      "source": [
        "session, input_name, output_name = load_model(model_path, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "383 frames detected!\n",
            "--- Frame inferred in 0.53 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.42 seconds ---\n",
            "--- Frame inferred in 0.41 seconds ---\n",
            "--- Frame inferred in 0.41 seconds ---\n",
            "--- Frame inferred in 0.40 seconds ---\n",
            "--- Frame inferred in 0.41 seconds ---\n",
            "--- Frame inferred in 0.57 seconds ---\n",
            "--- Frame inferred in 0.42 seconds ---\n",
            "--- Frame inferred in 0.25 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.48 seconds ---\n",
            "--- Frame inferred in 0.41 seconds ---\n",
            "--- Frame inferred in 0.39 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.51 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.43 seconds ---\n",
            "--- Frame inferred in 0.41 seconds ---\n",
            "--- Frame inferred in 0.40 seconds ---\n",
            "--- Frame inferred in 0.44 seconds ---\n",
            "--- Frame inferred in 0.41 seconds ---\n",
            "--- Frame inferred in 0.43 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.39 seconds ---\n",
            "--- Frame inferred in 0.41 seconds ---\n",
            "--- Frame inferred in 0.44 seconds ---\n",
            "--- Frame inferred in 0.41 seconds ---\n",
            "--- Frame inferred in 0.47 seconds ---\n",
            "--- Frame inferred in 0.44 seconds ---\n",
            "--- Frame inferred in 0.42 seconds ---\n",
            "--- Frame inferred in 0.54 seconds ---\n",
            "--- Frame inferred in 0.50 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.39 seconds ---\n",
            "--- Frame inferred in 0.44 seconds ---\n",
            "--- Frame inferred in 0.47 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.52 seconds ---\n",
            "--- Frame inferred in 0.39 seconds ---\n",
            "--- Frame inferred in 0.61 seconds ---\n",
            "--- Frame inferred in 0.41 seconds ---\n",
            "--- Frame inferred in 0.40 seconds ---\n",
            "--- Frame inferred in 0.44 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.46 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.54 seconds ---\n",
            "--- Frame inferred in 0.51 seconds ---\n",
            "--- Frame inferred in 0.50 seconds ---\n",
            "--- Frame inferred in 0.39 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.43 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.39 seconds ---\n",
            "--- Frame inferred in 0.40 seconds ---\n",
            "--- Frame inferred in 0.45 seconds ---\n",
            "--- Frame inferred in 0.43 seconds ---\n",
            "--- Frame inferred in 0.63 seconds ---\n",
            "--- Frame inferred in 0.67 seconds ---\n",
            "--- Frame inferred in 0.54 seconds ---\n",
            "--- Frame inferred in 0.40 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.52 seconds ---\n",
            "--- Frame inferred in 0.41 seconds ---\n",
            "--- Frame inferred in 0.50 seconds ---\n",
            "--- Frame inferred in 0.52 seconds ---\n",
            "--- Frame inferred in 0.56 seconds ---\n",
            "--- Frame inferred in 0.39 seconds ---\n",
            "--- Frame inferred in 0.45 seconds ---\n",
            "--- Frame inferred in 0.42 seconds ---\n",
            "--- Frame inferred in 0.41 seconds ---\n",
            "--- Frame inferred in 0.52 seconds ---\n",
            "--- Frame inferred in 0.43 seconds ---\n",
            "--- Frame inferred in 0.42 seconds ---\n",
            "--- Frame inferred in 0.30 seconds ---\n",
            "--- Frame inferred in 0.56 seconds ---\n",
            "--- Frame inferred in 0.44 seconds ---\n",
            "--- Frame inferred in 0.31 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.41 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.48 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.40 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.39 seconds ---\n",
            "--- Frame inferred in 0.32 seconds ---\n",
            "--- Frame inferred in 0.42 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.41 seconds ---\n",
            "--- Frame inferred in 0.40 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.42 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.46 seconds ---\n",
            "--- Frame inferred in 0.44 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.44 seconds ---\n",
            "--- Frame inferred in 0.46 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.48 seconds ---\n",
            "--- Frame inferred in 0.45 seconds ---\n",
            "--- Frame inferred in 0.50 seconds ---\n",
            "--- Frame inferred in 0.42 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.42 seconds ---\n",
            "--- Frame inferred in 0.55 seconds ---\n",
            "--- Frame inferred in 0.46 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.40 seconds ---\n",
            "--- Frame inferred in 0.47 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.39 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.39 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.43 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.39 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.40 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.43 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.44 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.41 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.39 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.44 seconds ---\n",
            "--- Frame inferred in 0.50 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.33 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.25 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.40 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.40 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.33 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.32 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.41 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.40 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.39 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.33 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.40 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.33 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.39 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.39 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.43 seconds ---\n",
            "--- Frame inferred in 0.33 seconds ---\n",
            "--- Frame inferred in 0.31 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.39 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.41 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.33 seconds ---\n",
            "--- Frame inferred in 0.40 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.22 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.41 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.33 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.41 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.43 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.33 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.41 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.40 seconds ---\n",
            "--- Frame inferred in 0.33 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.39 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.27 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.22 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.34 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.36 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.24 seconds ---\n",
            "--- Frame inferred in 0.37 seconds ---\n",
            "--- Frame inferred in 0.38 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Frame inferred in 0.45 seconds ---\n",
            "--- Frame inferred in 0.35 seconds ---\n",
            "--- Completed in 145.74 seconds ---\n"
          ]
        }
      ],
      "source": [
        "frame_predictions, bbox_class_score, orig_frames, origi_shape, fps = video_predict(\n",
        "    video_path, out_frames_path, \n",
        "    session, input_name, output_name, label_path,\n",
        "    (width,height), num_classes, conf_thre, nms_thre,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "video_stitch(frame_predictions, video_out_path, 'tmp', origi_shape, fps)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "35d4e6b4fb3df552e3cc73934b237aabcb33438f346e75c5e5ee50789f090e2e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
